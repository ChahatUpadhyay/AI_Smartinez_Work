{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlg128tjbK7xxs+L2qnu65",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChahatUpadhyay/AI_Smartinez_Work/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfnmOSp-khZ8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "path = \"/content/House Price India.csv\"\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Date' in df.columns:\n",
        "    df.drop(columns=['Date'], inplace=True)\n",
        "\n",
        "# Fill missing values\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'O':  # Categorical\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "    else:  # Numerical\n",
        "        df[col] = df[col].fillna(df[col].median())\n"
      ],
      "metadata": {
        "id": "xb9dGzZAlMRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode 'Label' column if it exists\n",
        "if 'Label' in df.columns:\n",
        "    le = LabelEncoder()\n",
        "    df['Label'] = le.fit_transform(df['Label'])\n",
        "\n",
        "# Splitting dataset into features (X) and target (y)\n",
        "# We'll predict 'Price'\n",
        "X = df.drop(columns=['Price'])\n",
        "y = df['Price']\n",
        "\n",
        "# Apply a log transformation to the target for better numerical stability\n",
        "y = np.log1p(y)  # log(1+y) transformation"
      ],
      "metadata": {
        "id": "In8-bwHHlQsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the simple ANN model using an explicit Input layer\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE (in log scale): {test_mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX7GCuKMlcXS",
        "outputId": "f5d00a95-e906-4080-88a5-dffcdc8bad1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 62.7273 - mae: 6.4274 - val_loss: 4.1160 - val_mae: 1.2302\n",
            "Epoch 2/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0153 - mae: 1.0907 - val_loss: 2.3463 - val_mae: 0.9285\n",
            "Epoch 3/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1605 - mae: 0.8274 - val_loss: 1.5193 - val_mae: 0.7355\n",
            "Epoch 4/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7319 - mae: 0.6536 - val_loss: 0.9068 - val_mae: 0.5599\n",
            "Epoch 5/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4208 - mae: 0.4960 - val_loss: 0.5220 - val_mae: 0.4077\n",
            "Epoch 6/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2122 - mae: 0.3540 - val_loss: 0.2956 - val_mae: 0.2981\n",
            "Epoch 7/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1164 - mae: 0.2586 - val_loss: 0.2070 - val_mae: 0.2304\n",
            "Epoch 8/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0700 - mae: 0.1965 - val_loss: 0.1344 - val_mae: 0.1824\n",
            "Epoch 9/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0469 - mae: 0.1590 - val_loss: 0.1059 - val_mae: 0.1450\n",
            "Epoch 10/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0333 - mae: 0.1350 - val_loss: 0.1030 - val_mae: 0.1523\n",
            "Epoch 11/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0277 - mae: 0.1207 - val_loss: 0.0804 - val_mae: 0.1114\n",
            "Epoch 12/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0220 - mae: 0.1059 - val_loss: 0.0802 - val_mae: 0.1091\n",
            "Epoch 13/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0178 - mae: 0.0958 - val_loss: 0.0774 - val_mae: 0.1078\n",
            "Epoch 14/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0198 - mae: 0.1002 - val_loss: 0.0720 - val_mae: 0.0969\n",
            "Epoch 15/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0173 - mae: 0.0920 - val_loss: 0.0679 - val_mae: 0.0987\n",
            "Epoch 16/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0187 - mae: 0.0972 - val_loss: 0.0680 - val_mae: 0.0853\n",
            "Epoch 17/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0144 - mae: 0.0828 - val_loss: 0.0612 - val_mae: 0.0894\n",
            "Epoch 18/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0136 - mae: 0.0816 - val_loss: 0.0548 - val_mae: 0.0792\n",
            "Epoch 19/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0797 - val_loss: 0.0556 - val_mae: 0.0948\n",
            "Epoch 20/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0111 - mae: 0.0749 - val_loss: 0.0569 - val_mae: 0.0911\n",
            "Epoch 21/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0125 - mae: 0.0767 - val_loss: 0.0524 - val_mae: 0.0815\n",
            "Epoch 22/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0097 - mae: 0.0683 - val_loss: 0.0478 - val_mae: 0.0714\n",
            "Epoch 23/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0104 - mae: 0.0709 - val_loss: 0.0473 - val_mae: 0.0814\n",
            "Epoch 24/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0110 - mae: 0.0716 - val_loss: 0.0551 - val_mae: 0.1055\n",
            "Epoch 25/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0638 - val_loss: 0.0438 - val_mae: 0.0694\n",
            "Epoch 26/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0098 - mae: 0.0671 - val_loss: 0.0423 - val_mae: 0.0826\n",
            "Epoch 27/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0100 - mae: 0.0679 - val_loss: 0.0522 - val_mae: 0.1131\n",
            "Epoch 28/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0093 - mae: 0.0686 - val_loss: 0.0440 - val_mae: 0.0791\n",
            "Epoch 29/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0091 - mae: 0.0669 - val_loss: 0.0386 - val_mae: 0.0588\n",
            "Epoch 30/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0076 - mae: 0.0586 - val_loss: 0.0453 - val_mae: 0.1126\n",
            "Epoch 31/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0091 - mae: 0.0665 - val_loss: 0.0372 - val_mae: 0.0726\n",
            "Epoch 32/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 - mae: 0.0630 - val_loss: 0.0350 - val_mae: 0.0700\n",
            "Epoch 33/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 - mae: 0.0626 - val_loss: 0.0427 - val_mae: 0.0930\n",
            "Epoch 34/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0088 - mae: 0.0642 - val_loss: 0.0315 - val_mae: 0.0557\n",
            "Epoch 35/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0555 - val_loss: 0.0386 - val_mae: 0.0840\n",
            "Epoch 36/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0572 - val_loss: 0.0361 - val_mae: 0.0842\n",
            "Epoch 37/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0600 - val_loss: 0.0341 - val_mae: 0.0877\n",
            "Epoch 38/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0066 - mae: 0.0539 - val_loss: 0.0311 - val_mae: 0.0706\n",
            "Epoch 39/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0070 - mae: 0.0556 - val_loss: 0.0290 - val_mae: 0.0760\n",
            "Epoch 40/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 0.0264 - val_mae: 0.0495\n",
            "Epoch 41/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0061 - mae: 0.0541 - val_loss: 0.0245 - val_mae: 0.0479\n",
            "Epoch 42/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0553 - val_loss: 0.0236 - val_mae: 0.0473\n",
            "Epoch 43/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0055 - mae: 0.0490 - val_loss: 0.0221 - val_mae: 0.0449\n",
            "Epoch 44/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0212 - val_mae: 0.0499\n",
            "Epoch 45/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0538 - val_loss: 0.0245 - val_mae: 0.0498\n",
            "Epoch 46/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0055 - mae: 0.0494 - val_loss: 0.0227 - val_mae: 0.0468\n",
            "Epoch 47/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0516 - val_loss: 0.0241 - val_mae: 0.0582\n",
            "Epoch 48/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0505 - val_loss: 0.0234 - val_mae: 0.0754\n",
            "Epoch 49/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0063 - mae: 0.0544 - val_loss: 0.0214 - val_mae: 0.0489\n",
            "Epoch 50/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0458 - val_loss: 0.0199 - val_mae: 0.0454\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 - mae: 0.0457\n",
            "Test MAE (in log scale): 0.04536919668316841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To interpret predictions in original scale, apply the inverse transformation\n",
        "y_pred = np.expm1(model.predict(X_test))\n",
        "print(\"Sample Predictions in original scale:\", y_pred[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcf5BABelfkm",
        "outputId": "a2a43c70-fb5c-4204-cd88-cac7c5c4022d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Sample Predictions in original scale: [[234119.27]\n",
            " [585770.1 ]\n",
            " [623422.5 ]\n",
            " [539133.06]\n",
            " [673535.6 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E03n2gz5l08L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}